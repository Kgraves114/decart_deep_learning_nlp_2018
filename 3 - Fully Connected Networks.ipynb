{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Fully Connected Networks\n",
    "\n",
    "### Fully connected networks are the classic starting point of neural networks. This is how word embedings are created. \n",
    "\n",
    "### Fully connected network consists of \n",
    "* Input layer\n",
    "* Several hidden layers\n",
    "* Output layer\n",
    "\n",
    "### Again we will illistrate this classical method using the MNIST dataset. This could jest as easily be radiograph images although a great deal of data prepartation is done for us.\n",
    "\n",
    "\n",
    "<BR>\n",
    "<BR>\n",
    "<img src=\"./images/fully-connected.png\" width=\"400px\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This time we have to define an activation function for the output of our hidden layer. \n",
    "\n",
    "#### Why do we use the Sigmoid function instead of the step function?\n",
    "\n",
    "<BR>\n",
    "<img align=\"left\" style=\"float: l;\" src=\"./images/sigmoid-function.png\" width=\"350px\">\n",
    "<img style=\"float: l;\" src=\"./images/sig-derivative-graph.png\" width=\"400px\">\n",
    "<img src=\"./images/sigmoid derivative.png\" width=\"300px\">\n",
    "<BR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This convenience function will randomly initialize our weights  to values from a normal distribution \n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the previous dataset with a new dataset of cases\n",
    "def update_d(prev, new):\n",
    "    combined = prev.copy()\n",
    "    combined.update(new)\n",
    "    return combined \n",
    "\n",
    "# We will define a fnction to train our model and display how it is doing\n",
    "def train_model(sess, train_X, train_Y, test_X, test_Y, train_operation, accuracy_operation, num_epochs, batch_size, test_size):\n",
    "    accuracies = []\n",
    "    train_feed = dict()\n",
    "    test_feed = dict()\n",
    "    startingTime = time.time()\n",
    "    with tqdm.tqdm(total = num_epochs * len(train_X)) as ranger:\n",
    "        for epoch in range(num_epochs): # An epoch is a run through our entire training data set\n",
    "            for start in range(0, len(train_X), batch_size): # loop in batches of batch size\n",
    "                end = start + batch_size\n",
    "                sess.run(train_operation, feed_dict=update_d(train_feed, {X: train_X[start:end],y: train_Y[start:end]}))\n",
    "                ranger.update(batch_size)\n",
    "                if (start // batch_size) % 100 == 0: # Let's record accuracy every batch\n",
    "                    testSet = np.random.choice(len(test_X), test_size, replace=False)\n",
    "                    tstX, tstY = test_X[testSet], test_Y[testSet]\n",
    "                    accuracies.append(sess.run(accuracy_operation, feed_dict = update_d(test_feed, {X: tstX, y: tstY})))\n",
    "                    ranger.set_description(\"Test Accuracy: \" + str(accuracies[-1]))\n",
    "            # print out the final test accuracy                                                       \n",
    "            testSet = np.random.choice(len(test_X),test_size,replace=False)\n",
    "            tstX, tstY = test_X[testSet], test_Y[testSet]\n",
    "            accuracies.append(sess.run(accuracy_operation, feed_dict = update_d(test_feed, {X: tstX, y: tstY})))\n",
    "            ranger.set_description(\"Test Accuracy: \" + str(accuracies[-1]))\n",
    "    timeTaken = time.time() - startingTime\n",
    "    print(\"Finished training for %d epochs\" % num_epochs)\n",
    "    print(\"Took %.02f seconds (%.02f s per epoch)\" % (timeTaken, timeTaken/num_epochs))\n",
    "    accuracies.append(sess.run(accuracy_operation, feed_dict = update_d(test_feed, {X:test_X, y: test_Y})))\n",
    "    print(\"Final accuracy was %.04f\" % accuracies[-1])\n",
    "    plt.plot(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A placeholder is not a value! We just need to define how we will hold onto our training cases. \n",
    "# \"None\" means that this dimension can be any length.\n",
    "\n",
    "# X will be our input placeholder for a image case\n",
    "X = tf.placeholder(\"float\",shape=[None,784])\n",
    "# Y will be a placeholder for our output distribution\n",
    "y = tf.placeholder(\"float\",shape=[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will define our weight variables coming into the hidden layer and entering the output layer\n",
    "# We take advantage of the convenience function init_weights to do this work.\n",
    "NUM_HIDDEN = 620\n",
    "W_h = init_weights([784,NUM_HIDDEN]) # Weights entering the hidden layer\n",
    "W_o = init_weights([NUM_HIDDEN,10]) # Weights entering the output layer\n",
    "b_h = init_weights([1, NUM_HIDDEN]) # Let's define our bias weights for the hidden layer\n",
    "b_o = init_weights([1, 10]) # Let's define our bias weights for the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate our weights between the input layer and the hidden layer\n",
    "entering_hidden = tf.matmul(X,W_h) + b_h\n",
    "# Let's execute our activation function on the hidden layer neurons\n",
    "exiting_hidden = tf.nn.sigmoid(entering_hidden)\n",
    "#Let's calculate our weights between the output of the hidden layer nad the input into our softmax output layer\n",
    "y_hat = tf.matmul(exiting_hidden,W_o) + b_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we need to train our model\n",
    "\n",
    "#### First we have to understand what it means  for a model to be good! IN machine learning we actually define what it means for a model to be bad. We call this our cost of loss function. Our goal is to minimize our loss.\n",
    "\n",
    "#### A commonly used loss function is \"cross-entropy\". Cross-entropy loss increases as the predicted probability diverges from the actual label. It looks something like this . . .\n",
    "\n",
    "<BR>\n",
    "<img src=\"./images/cross_entropy.png\" width=\"400px\"> \n",
    "<BR>\n",
    "\n",
    "<center>$H_{y'}(y) = - \\displaystyle \\sum_{i} y'_i \\space log(y_i) $</center>\n",
    "\n",
    "#### Where  <i>y</i> is our predicted probability distribution, <i>y'</i> is our true distribution (the one-hot vector with the digit labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When we calcualte our evidence we end up with unnormalized log probabilities such as below . . .\n",
    "\n",
    "$evidence_i = \\displaystyle \\sum_{j=0} p(\\space W_{i,j} \\space x_j \\space + \\space b_i) $\n",
    "\n",
    "#### Let's assume a 3 class problem . . . \n",
    "* Training Case 1 Prediction: [ 0.5,  1.5,  0.1]\n",
    "* Training Case 2 Prediction: [ 2.2,  1.3,  1.7]\n",
    "\n",
    "#### These outputs do not sum to one, that is they are unromalized probabilities\n",
    "\n",
    "#### Now Softmax is going to normalize these into linear probabilites\n",
    "\n",
    "$y_{hat} = softmax(evidence)$\n",
    "\n",
    "* Training Case 1 Softmax: [0.227863, 0.61939586, 0.15274114]\n",
    "* Training Case 2 Softmax: [0.49674623,0.20196195,0.30129182]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can define our loss function. Cross entropy with logits and we average across our batch.\n",
    "# We generate unnormalized log probabilities (aka logits) and we want the outputs normalized linear probabilities\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent\n",
    "<BR>\n",
    "<img align=\"left\" style=\"float: l;\" src=\"./images/gd.png\" width=\"400px\">\n",
    "\n",
    "<img style=\"float: l;\" src=\"./images/gd-learning.png\" width=\"350px\">\n",
    "<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our gradient descent optimizer\n",
    "# We want to minimize our loss function, that is cross entropy. We will set a learning rate of 0.5\n",
    "train_operation = tf.train.GradientDescentOptimizer(0.2).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Let's read in our MNIST data\n",
    "mnist = input_data.read_data_sets(\"data\", one_hot=True)\n",
    "trX, trY = mnist.train.images, mnist.train.labels\n",
    "tstX, tstY = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9783: 100%|██████████████████████████████████████████████| 2750000/2750000 [03:21<00:00, 13660.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training for 50 epochs\n",
      "Took 201.32 seconds (4.03 s per epoch)\n",
      "Final accuracy was 0.9783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt8VNW99/HPL3cSSIAQruEuFVAQBBG0KooXtF6r7cF6bT2leqq1F9vqaaseWp+257THY59a+qAi1WO11p5ajlLRKt5RiHJX0YAI4SKBkEhIyG1+zx+zM5lMJmGUEEjm+3695jWz1157Z60Q9m/WZa9t7o6IiEjK4S6AiIgcGRQQREQEUEAQEZGAAoKIiAAKCCIiElBAEBERIMGAYGbzzWynma1tZb+Z2W/MrNjMVpvZ8VH7rjGzD4LXNVHpk8xsTXDMb8zMDr46IiLyWSXaQlgAzGxj/7nAqOA1G5gLYGa9gTuAE4EpwB1m1is4Zm6Qt/G4ts4vIiKHWEIBwd1fBsrayHIR8JCHvQH0NLMBwDnAc+5e5u57gOeAmcG+XHdf6uE74x4CLj6omoiIyEFJa6fzDAK2RG2XBGltpZfESW/BzGYTbkmQk5MzafTo0e1UZBGR5PDWW2/tcveCA+Vrr4AQr//fP0N6y0T3ecA8gMmTJ3tRUdFnLaOISFIys48Syddes4xKgMFR24XAtgOkF8ZJFxGRw6S9AsJC4OpgttFUoMLdtwOLgbPNrFcwmHw2sDjYt9fMpgazi64G/tZOZRERkc8goS4jM3sUmA70MbMSwjOH0gHc/ffAIuA8oBioAr4a7Cszs58Cy4NTzXH3xsHpGwjPXuoG/D14iYjIYWKdaflrjSGIiHx6ZvaWu08+UD7dqSwiIoACgoiIBBQQREQEUEAQEZGAAoKIiAAKCCIiElBAEBERQAFBREQCCggiIgIoIIiISEABQUREAAUEEREJKCCIiAiggCAiIgEFBBGRw6ghFP8RBPUNITr68QTt9UxlEZEOt6+mntr6EL1yMpql1zeEqKypp2d28/Tq2gZK9lQxql+PSFoo5BR9tIelG3Zzw/SRZKSlRPKu3FLOE2+V8P1zjqZ/XhYAtfUhFq/bwQvv7eTmGaMY1ieHfTX17Kmq5eX3d/Fa8S6uP20k4wrzCIWcFVv28MzaHby7fS+zTx3BqZ8rYEfFfha8vonn3/2YD3ZWMvvUEdx27mh2VdbyvT+vYvmHZVTXNXDW2H7MveJ40lI75ru7HpAjIgnbV1NPTmbT98iq2nqyM9LYUbGffrmZmBlVtfU88sZmzh3Xn4y0FPrkZJKSYmzeXcV/v/kRXxg3gOKdlYwe0INjBuaxdmsFc/73HW484yh+/9IGxg3K47bzxrBnXy3femwFr3ywC4CLJgzknlkTqalv4IdPrObJleHHsGekpbDsX2eQlZ7Kdx9fyQvv7WR/XYgUgz98bQonjezDj/66huKdlRR9tAeAiycM5PYLjuFXz67npfWlbC2vBmDS0F58/5yj+evbW/lT0ZZmdf8/l4xjY2klfyrawt799QCkpRhXnDiENzaWsf7jvc3yX3vSMN7YuJv3djRP/6fJg/nf1duoqm1olj4sP5tNu6ta/M7/afJgfnHpOMJPG/5sEn1AjgKCSBdRXlXLlrJqxhXmRdJq60MUbSrjne2fcN3nh0cuKhVVdTyy7COeWbuDBV+dQu+cDPbV1LN2awXzX/uQVz7YxZPfPJmstFRe37CLp1Zv59Xi8IX56mlD+fopI3jwtU3Mf+3DyM/68uRCfjBzNN9+bGUkL8AXJw7iWzNGcd8rG3nkzc3NyvzlyYWkpabwx5j0aSPyyUxP4cX1pc3S87qlU1sforqu+cX0YAzLz6a6roG+PbLYXlHNrsraZuWrDzn/8/bWSFpWegqXTSqkoHsWb2zczdKNuwHIzkjlus8PJy0lhaKPyiKBrFd2Ovd+5Xi2llfzWvGuSCADePGW6aSYMf+1D1nw+iYAxhfm8cT1J5GaYtzzj/f5zQvFDO7djT/+81QG987+THVs14BgZjOBe4BU4H53/0XM/qHAfKAAKAOudPcSMzsduDsq62hglrs/aWYLgNOAimDfte6+sq1yKCBIV9T4fzD6G6C7t/hGWLSpjPKqOnpkpVEfck4amY+Z8cCrHzLv5Q18/EkNAA99bQonH9WHuS8W86tn348c/43TRlBWWcuuyhqWRF1oTz+6gL49slp8I05UVnoK++tCLdLzuqVTUV3X6nH9c7PY8cl+ALqlp9LgTm19iOF9cvhw1z4Aeman8+0Zo3h7cznD8rN5dPkWSvfWMCAviz9+fSppKUZpZQ3/tnAdq0oq6J+bxcPXTWF4nxz214f4wROrWLRmBzkZqTz1rVMY0jub1BTj3iXF/Mfi9YwdkMsTN0wjOyPc6nn+3Y+57g9F9MxO5+83n8KAvG4AvL5hF1+570365Way8MbP0y833H1UvLOSM//zJUYU5PDY16fSN0jfVl7NOXe/zIiCHO67enIkvWxfLcf/9DkAnvzmyUwY3BMIjyNc++AyCntlc+vM0eRlpwPhv4PfvlDMii3l/OziYxnYs9tn+jdqt4BgZqnA+8BZQAmwHLjc3d+JyvNn4Cl3/4OZnQF81d2vijlPb6AYKHT3qiAgPOXuTyRaKQUE6Qze2LibkQXdKeiRCYS/uXfLSOWvb28lJcU4Z2x/8rLTWfLeTvp0z+T/LHqXpRt3c8+sCUwZ3purH1jGnqo6xhfm8cJ7O7lk4iAunjiIa+Yva/ZzhuZn069HFss2lR3yOk0/uoBzj+1Pfk4md/7vOkr2hLtY/vnzw/ne2Ufz8SfhPvGnVm9nV2UN937leL4wfgD76xoo2rSHR5dtxnGu+/wIjh8SvgiaGb97sZj3d+zlskmD+fyoPpGf98zaHSzdsIsvjB/IlOG9I+lbyqpYv2Mvo/p1Z2h+TiS9sqaeHRX7yeuWHvm9Q/hCu3tfDe5ELuIQvtBW1zVEAkEi9tc1kJWe+ul/eTEqa+rJyUg9qC6gT6s9A8I04E53PyfYvg3A3X8elWcdcE7QKjCgwt1zY84zGzjN3a8ItheggCBHsO0V1ZFviI327q/jgv/7Kj/+wlje2f4JFxw3kGH52eyrbeDLv1/KlOG9WfD6JjLTUnjp+6fTLT2V4+Y8y+j+PSJ9yWeO6cfg3t148LVN7VbWo/p256SR+ZTtq+Wp1dsj6TdMH8m4QXkc1bc7Z9/9ciR9/rWTOa6wJ/ndM/nD65tIT01hX00915w0jPRUw8x4eOkmdu+rpXtmGlecOJRuGU0XQ3fnmbU7OH1033a5SMqh1Z4B4TJgprv/c7B9FXCiu98YleePwJvufo+ZfRH4C9DH3XdH5XkB+E93fyrYXgBMA2qA54Fb3b2mrbIoIMjBcneqahsiA6OhkLNsUxlD87N5dt3HfGlyIdkZaawuKefC377GMQNz2by7illTBnPeuAE8/MZHzfqTAQbkZbG9Yv8Bf/bAvCy2xeQ7+ah8RvXtQWllDU8HF/IbTz+KYwflcfzQnqzfsZerHlhGfk4Gl04q5PzxAzhmYB6V++u58oE3GTsglzEDenDtycMj9blj4TomDe1FQ8i5dFJh5Gct31RGYa9upJg1+7YsXV97BoQvEf72Hx0Qprj7TVF5BgK/BYYDLwOXAse4e0WwfwCwGhjo7nVRaTuADGAesMHd58T5+bOB2QBDhgyZ9NFHHx2oTpJEautD7KjYz5D85oNtxTsreX3DLq48cSgpKcbKLeX85Mm1ZKSl8NZHe/jGqSP4wczR/HXFVm7586rIccPys/npxcfy2PItkQt0a6K/9Tf61oxRXHjcQH73YnEkcJx7bH9O+1wBlxw/iJWby/mXR94mJzONf79sPFNH5APhvuVfP7ueG6aPpLBX87qU7q1p1g0i8ml1aJdRTP7uwHvuXhiVdjPhADG7lWOmA7e4+/ltlUUthOS185P9bKvYHxmEC4Wcytp6Lpv7Ou9/XMmyH82gb48s/vHOx/z6ufd5d/snAPTpnsGSW6Zz5QPLWLWlvNk583MyyEpPZWt5ddyLe/fMNH568TGcfnRfJsx5LpJ+0sh8fv3l4xiQ140X3vuYv7y1lfLqWr5+ygimH90XCPc3r91awdiBuWSlpZKS0nH9xSKx2jMgpBEeVJ4BbCU8qPwVd18XlacPUObuITO7C2hw99uj9r8B3ObuS6LSBrj79mDM4W5gv7vf2lZZFBC6rvKqWmobQtz/yofs2VfLf3zpONyde5cU88n+eua9vBGAv998CtkZqdz2P2t4fcPuZuc4aWR+i7RYU0f05vzxA/nxk2uB8Bz2/3fVJE4PLuTDbn0agMunDOamM0ZFZnWs2LyHzWVVpJhx2tEF5Galt2v9RQ6lRAPCAYfY3b3ezG4EFhOedjrf3deZ2RygyN0XAtOBn5uZE+4y+mZUQYYBg4GXYk79iJkVAAasBK5PoF7Sya0pqSArPYXfLimmV3YGd154DHUNIc66+2VK9zYNIV0xdShpKdZs2iTAufe80uq5G4PBHReMZUBeN0r2VPGzp98FYMqw3tw9awL9emSSlppCVnoqGWkpnD22X7NB0cXfPpXa+lCzufwAE4f0YuKQXgddf5EjmW5Mk0OiurYBM5pdbKPnYDd65Qens7msiivuf7PFOaLnqcfz4LUnUFlTz02PrgDgskmFnDQyn0smDopM6SvbV0t2RqpmwkhSa7cWgsinVVPfwDn/9TJVtQ2cfnQBIwq6c8XUISxet6NF3lP+PdKLyBmj+/LCezsj243B4C83TOO9HXtZU1LBGxt3c8bofpRX1XL66HA3z/njB+AOZs1v7gLoHbPGjYi0TgFBDsryTWUsXLmNHllpnDduAMcOymPRmu1sLguvyfLnt0oA+OUz7wGQm5XGuccOYNGa7eytqY+cJzcrjQeumUxFdR2z5r3BD2Yezai+Pdhf18Cofj2YNLQ3nBi/DGZGB97jI9JlqctIErK6pJy3P9rDtScPJxRyzGBfbQPH3rG4Wb4+3TPYVVlLt/RULjhuAI8XlTTb/7WTh3P7BWPZX9fAg69t4rjBeWSmpZKZlsKxg5r324tI+9DidtJuGkLOyH9dBEBhr26U7KmOXPhbk52RyjtzZrLzk/387sUNTB7Wi5nH9O+wZXxFpInGEOQz2VVZw76aeobm57ClrIrcbums3VoR2d+4hk10MLj9/LE88OqHbC2vZsyAXE4amR+54apvbhZ3XnhMx1ZCRD4TBQSJKK+qZfLP/pFQ3pyMVPYF67l/7fPDuWjCQF7+oJSLJwxqMbArIp2DAkKSqqiqIyUlvKrk+eMH0uDeYq36aNkZqTz0tSnU1Id4Y+NuvnPm5xh352JumjEKgPzumVwysbDV40XkyKcxhCS0pqSCC+99lUT+6V/43mmc8euXOHNMX+6/5oRDXzgRaXcaQxAAKqrrqKlr4Ok127lq6lDSUlOY98rGVoPBtBH5jB+cxwXjB5KVnsqIgu7cf/VkTohak15EuiYFhC7M3Tnu356NbD/y5maO7teDp9dsZ2RBDhtK90X2Lb3tDL77p1XcceFYRvdv9igLzhzbr8PKLCKHj+YAdjHRXYCxz6Mt3lnJ02vCSzpfNGEQy390ZmTfgLxuPDp7aotgICLJQy2ELuKrDy6jrKqOVVvK+bcLj+HqaUP5j8XrW+S7Z9YEbn5sJecc05+CHpm8dusZVNe23wPLRaTz0qByF1BeVdtsvX6AHplpzZaGaLTpF1/oqGKJyBEi0UFldRl1AW99tKdFWmMwuHnGKC44biAAPbO1hr+ItE5dRp1QRVUdyzeVMa4wj365Wfw65pkB0Y4ZmMt3zvocP//iOHS7mIi0RQGhE3F3xt6+mOq6pj7/Z79zKu8Ej4uMtuSW6dyxcB3TRoaXkOieqX9qEWmbuow6ka3l1c2CAcDZd78MhLuGhvRuejj78D45PPS1KfTQox5FJEEKCJ3IVx9cHjfdLLys9Ms/OL2DSyQiXYn6ETqJypp6PthZ2SL9++cczddOHk63jPAjIv/90vEMjmopiIgkKqGAYGYzgXuAVOB+d/9FzP6hwHygACgDrnT3kmBfA7AmyLrZ3S8M0ocDjwG9gbeBq9y99QX2k9DDSzcxsm93cOiflxU3zzdPP6rZ9pdPGNwBJRORruiAAcHMUoF7gbOAEmC5mS1093eisv0KeMjd/2BmZwA/B64K9lW7+4Q4p/4lcLe7P2ZmvweuA+YeRF26jP11Dcz49UtsLa9use/YQbms3dpyEFlE5GAlMoYwBSh2943BN/jHgIti8owFng8+L4mzvxkLL5h/BvBEkPQH4OJEC93VFe+sjBsMAH79pQms+MlZHVwiEUkGiQSEQcCWqO2SIC3aKuDS4PMlQA8zyw+2s8ysyMzeMLPGi34+UO7ujbfSxjsnAGY2Ozi+qLS0NF6WLmfxuh2t7uufm0WvnAwALpuk5w+ISPtJZAwh3v1Msetd3AL81syuBV4GtgKNF/sh7r7NzEYAL5jZGiBen0fcNTTcfR4wD8JLVyRQ3k7t40/2839fKG6Wlp+TwV2XjOOJt0rI7Rb+J/vgrnNJ1ZPJRKQdJdJCKAGiRyoLgW3RGdx9m7t/0d0nAj8K0ioa9wXvG4EXgYnALqCnmaW1ds5ksa+mnkvnvh55bvHbcZahAJh5bH/uv2Zy5PGU6akppKQoIIhI+0kkICwHRpnZcDPLAGYBC6MzmFkfM2s8122EZxxhZr3MLLMxD3Ay8I6HV9RbAlwWHHMN8LeDrUxnU1sfYta8N3jroz1c++AyvvCbV7jhkbdJTTF+OHN0JF+XbxaJyBHhgAEh6Oe/EVgMvAs87u7rzGyOmV0YZJsOrDez94F+wF1B+higyMxWEQ4Av4ianfRD4LtmVkx4TOGBdqpTp/HCex+zJmgZ7KqsZd22cE/a108ZwQ3TR7LklulA82cciIgcKgndh+Dui4BFMWm3R31+gqYZQ9F5XgfGtXLOjYRnMCWtsn11LdImDO7JD2ceDUCPrPA/T4rGCkSkA+hO5cPE3bn/1Y3N0qYM783j35gW2e6dncEVJw5h1glDOrp4IpKEtJZRB9m5dz8z/+tlNu+uAmDdtk/YGPVMY2i5ImlKinHXJeMYV5jXYeUUkeSlgNBBFq7cxns79vJA0CoojrMukcYKRORwUkDoIFnp4cXn9teFKK+q5Zm14ZvPFn3rFK6aOhSA+pACgogcPgoIHWDTrn38+Mm1ALy+cRcT5jzHM+t2kNctnbEDc5kxpi8AaiCIyOGkgNABHlvetPLHlrKmNYruvyb8zOvU4AazBrUQROQw0iyjQ2xreTW/f2lDs7Q+3TOYf+0JjC/sCcC4QXmYwfXTRx6OIoqIAAoIh9zTq1uuyDFxSK9IMADomZ3Bhz//QkcWS0SkBXUZHWIfBdNMo+XqOccicgRSQDiE6hpCvPLBLk4+Kp/om40b70AWETmSKCC0M3cnFAwOv1q8i81lVVw1dSir7jib608LjxFkpOnXLiJHHn1VbUfPrN3O9f/9NgCLv30qq7aUYwanjCogJzON3jnhrqKQZhOJyBFIAaEd/SlqeuncF4t5cuU2RhbkkJPZfJE6xQMRORKp76Id7attiHx+cmV4dtE3Tm2aSpoZdBWlp2r1UhE58qiF0E7+89n1LPuwrFna6UcX8OUTmh4296XJg9lQuo9/Of2oji6eiMgBKSC0A3fnNzHPQYbw/QXRstJTufPCYzqqWCIin4q6jNpBaWUNAAU9Mpul52SmHo7iiIh8JgoI7aBxKeu7vzyhWXr3TN2AJiKdR0IBwcxmmtl6Mys2s1vj7B9qZs+b2Woze9HMCoP0CWa21MzWBfv+KeqYBWb2oZmtDF4TYs97JHJ3dlXW8NZHTeMFG4IH3Yzsm9Msb3e1EESkEzlgQDCzVOBe4FxgLHC5mY2NyfYr4CF3Hw/MAX4epFcBV7v7McBM4L/MrGfUcd939wnBa+VB1qVD3P3c+0z+2T+4dO5S7ns5/LCbDTsryclIpX9uFn/9l5OYNLQX0PIJaCIiR7JEWghTgGJ33+jutcBjwEUxecYCzweflzTud/f33f2D4PM2YCdQ0B4FP1yiB4/vWvQuz7/7MQte30T/vCzMjIlDenFUQXcAMtPVQhCRziORgDAI2BK1XRKkRVsFXBp8vgToYWb50RnMbAqQAUSvBX1X0JV0t5k1H5FtOm62mRWZWVFpaWkCxT104j3i8q5F7wJwwrDekbTGdYv0wBsR6UwSCQjx7qKKvdTdApxmZiuA04CtQH3kBGYDgIeBr7p7KEi+DRgNnAD0Bn4Y74e7+zx3n+zukwsKDm/jYm9NfYu0jaX76NM9U9NJRaTTSyQglACDo7YLgWaL/Lv7Nnf/ortPBH4UpFUAmFku8DTwY3d/I+qY7R5WAzxIuGvqiLZrb3h66bQRzRo/TBuZH3lmMkBet/DsouwMdRmJSOeRyKjncmCUmQ0n/M1/FvCV6Axm1gcoC7793wbMD9IzgL8SHnD+c8wxA9x9u5kZcDGw9mArc6jtqqwF4J9PGc7Sjbsj6b2zm08vvfnMUfTKyeCC4wZ2aPlERA7GAVsI7l4P3AgsBt4FHnf3dWY2x8wuDLJNB9ab2ftAP+CuIP3LwKnAtXGmlz5iZmuANUAf4GftVan29PL7pVy3YHlkuinAwJ7dmuXJiZlNlJ2RxvWnjYw8K1lEpDNIaF6kuy8CFsWk3R71+QngiTjH/Tfw362c84xPVdLDoL4hxNXzlwHwSXU967ZVANCneybfOfNz3P2P94GWAUFEpDPSncpxhELOVQ+8yVE/+nskbfsn1cx/dRMnjcynT/cMbj5zFFOCmUUaKxCRrkABIY7y6jpe+WBXs7SX1pdSXdfA1dOGYcG8Ug8mW6mFICJdgQJCHHuqalukLVqzHYDJw3pF0hrvM8jJUEAQkc5PASGO8iAgXDNtaCRtVUkF4wvz6NO96f65xpsxsrVmkYh0AQoIgdUl5fzxzc0A7NlXB8DwPs0Xq4u9/6DxzuVsLVEhIl2A+joCF/72NQC+cuKQSJfRsJiAkNut+f0GjS0ETS8Vka5ALYQYDSGnvCp+CyF29VKtVSQiXYkCQox9tfWUVtaQlmIMirkBLXZ66X9cNp5zj+3P+MKeiIh0dgoIMSr31/PqB7uYOKQnaakpPPPtUyL7YlsIo/r1YO6Vk8hI069RRDo/XclivP/xXt7Z/gkzxvQDYHT/3MgFP1v3G4hIF6aAAFTXNkQ+/21leCHXM8f0bZFPj8QUka4s6QPC/67axpjbn4lsv7FxN71zMhgZPPUMmh4Ika0b0ESkC0v6gHDToyuabW+v2E9hr26R5Smg6QloekayiHRlSR0Q9tc1xE0fmNd8dpEFbQQtYiciXVlSB4QdFfsBOGVUn2bpsc87GF+YB2gROxHp2pL6ClcVDCYX9spult4/L7PZ9ryrJ7N+x95mj8kUEelqkrqFUF1XD0DfHs0DQGxLIK9bOlOG9+6wcomIHA5JHRD21YRbCIN7N28hdFNLQESSUEIBwcxmmtl6Mys2s1vj7B9qZs+b2Woze9HMCqP2XWNmHwSva6LSJ5nZmuCcv7HoaT0dpLHLaMyAHjxwzeRIugaPRSQZHTAgmFkqcC9wLjAWuNzMxsZk+xXwkLuPB+YAPw+O7Q3cAZwITAHuMLPGJ8zMBWYDo4LXzIOuzafU2GWUnZEWuTMZ0FiBiCSlRFoIU4Bid9/o7rXAY8BFMXnGAs8Hn5dE7T8HeM7dy9x9D/AcMNPMBgC57r7Uww8VeAi4+CDr8qk1dhnlxLQIdAOaiCSjRALCIGBL1HZJkBZtFXBp8PkSoIeZ5bdx7KDgc1vnBMDMZptZkZkVlZaWJlDcxDUuWdEtJiBoDEFEklEiASFe337skwBuAU4zsxXAacBWoL6NYxM5ZzjRfZ67T3b3yQUFBQkUNzHbyqtZtqkMaNkiiA0QIiLJIJG+kRJgcNR2IbAtOoO7bwO+CGBm3YFL3b3CzEqA6THHvhicszAmvdk5D7Uf/mU1r3ywC2j5xDMNKotIMkqkhbAcGGVmw80sA5gFLIzOYGZ9zKzxXLcB84PPi4GzzaxXMJh8NrDY3bcDe81sajC76Grgb+1Qn4TVN7T+uDN1GYlIMjpgQHD3euBGwhf3d4HH3X2dmc0xswuDbNOB9Wb2PtAPuCs4tgz4KeGgshyYE6QB3ADcDxQDG4C/t1elEtHWMhTqMhKRZJTQdBp3XwQsikm7PerzE8ATrRw7n6YWQ3R6EXDspylse6ptCDFmQC5/vn5ai32ZegKaiCShpL3y1dWH6J6ZGndJ68Nwj5yIyGGXtBPuaxtCZKU3j4f/+O5pvLfjk8NUIhGRwyt5A0J9iNys5tU/qm93jurbvZUjRES6tuTtMmoIkZ6atNUXEWkh6VoI9Q0hGtyprQ+RocFjEZGIpAsIl859nVUlFRT26qaAICISJemuiKtKKoDwGEKGuoxERCKS9opYXdugFoKISJSkvSLuranXoLKISJSkviKqhSAi0iSpr4gaQxARaZLUV0S1EEREmiT1FVEtBBGRJkl1RQyFmj8DQS0EEZEmSXVF3F/f0Gxbs4xERJok1RWxqrZ5QFALQUSkSVJdEatrY1sIeu6BiEij5AoIdc0Dgp6MJiLSJKEropnNNLP1ZlZsZrfG2T/EzJaY2QozW21m5wXpV5jZyqhXyMwmBPteDM7ZuK9v+1atpZq6ULNtdRmJiDQ54GqnZpYK3AucBZQAy81sobu/E5Xtx8Dj7j7XzMYSfv7yMHd/BHgkOM844G/uvjLquCuCZyt3iNoGDSqLiLQmkSviFKDY3Te6ey3wGHBRTB4HcoPPecC2OOe5HHj0sxa0PdTUx7QQFBBERCISuSIOArZEbZcEadHuBK40sxLCrYOb4pznn2gZEB4Muot+Yq082d7MZptZkZkVlZaWJlDc1tXGBgR1GYmIRCRyRYx3ofaY7cuBBe5eCJwHPGxmkXOb2YlAlbuvjTrmCncfB5wSvK6K98PdfZ67T3b3yQUFBQkUt3WxAUFdRiIiTRK5IpYAg6O2C2nZJXQd8DiAuy9IrHRAAAAM+klEQVQFsoA+UftnEdM6cPetwfte4I+Eu6YOqdqG5gFBs4xERJokckVcDowys+FmlkH44r4wJs9mYAaAmY0hHBBKg+0U4EuExx4I0tLMrE/wOR04H1jLIaYWgohI6w44y8jd683sRmAxkArMd/d1ZjYHKHL3hcD3gPvM7DuEu5OudffGbqVTgRJ33xh12kxgcRAMUoF/APe1W61aoTEEEZHWHTAgALj7IsKDxdFpt0d9fgc4uZVjXwSmxqTtAyZ9yrIetNguIwUEEZEmSXVFjL0xTV1GIiJNkuqKqEFlEZHWJdUVMfbGNLUQRESaJNUVsbY+1Ozu5NQUrXYqItIo+QKCuolEROJKqqtjbUODAoKISCuS6upYWx/SQLKISCuS6uqoLiMRkdYl1dWxtiE8qBx/XVURkeSW0J3KXUV9g5OWmsKb/zqDfTUNBz5ARCSJJFVACDmkGPTtkQU9DndpRESOLEnVZeTupKi/SEQkrqQKCCF3dC+aiEh8SRUQGhxaeVKniEjSS6qA4GohiIi0KqkCQshd6xeJiLQiuQJCSF1GIiKtSa6AoC4jEZFWJRQQzGymma03s2IzuzXO/iFmtsTMVpjZajM7L0gfZmbVZrYyeP0+6phJZrYmOOdvrAO+urujaaciIq04YEAws1TgXuBcYCxwuZmNjcn2Y+Bxd58IzAJ+F7Vvg7tPCF7XR6XPBWYDo4LXzM9ejcQ06D4EEZFWJdJCmAIUu/tGd68FHgMuisnjQG7wOQ/Y1tYJzWwAkOvuS93dgYeAiz9VyT+DkLvWMRIRaUUiAWEQsCVquyRIi3YncKWZlQCLgJui9g0PupJeMrNTos5ZcoBzAmBms82syMyKSktLEyhu60Kup6SJiLQmkYAQ7wrqMduXAwvcvRA4D3jYzFKA7cCQoCvpu8AfzSw3wXOGE93nuftkd59cUFCQQHFbp6UrRERal8jidiXA4KjtQlp2CV1HMAbg7kvNLAvo4+47gZog/S0z2wB8Ljhn4QHO2e40y0hEpHWJtBCWA6PMbLiZZRAeNF4Yk2czMAPAzMYAWUCpmRUEg9KY2QjCg8cb3X07sNfMpgazi64G/tYuNWpDg+5DEBFp1QFbCO5eb2Y3AouBVGC+u68zszlAkbsvBL4H3Gdm3yHc9XOtu7uZnQrMMbN6oAG43t3LglPfACwAugF/D16HlJauEBFpXULPQ3D3RYQHi6PTbo/6/A5wcpzj/gL8pZVzFgHHfprCHqyQxhBERFqVZHcqQ4qaCCIicSVZQFALQUSkNUkVEDx4hKaIiLSUVAGhIaQWgohIa5IqIGjpChGR1iVVQNBqpyIirUuqgBByJ1UBQUQkrqQLCClJVWMRkcQl1eVRS1eIiLQuqQKClq4QEWldUgUE3ZgmItK6JAsImmUkItKaJAsIaiGIiLQmqQKClq4QEWldUgWEhpBrtVMRkVYkVUDQ0hUiIq1LqoCgpStERFqXVAEhpPsQRERalVBAMLOZZrbezIrN7NY4+4eY2RIzW2Fmq83svCD9LDN7y8zWBO9nRB3zYnDOlcGrb/tVKz6tZSQi0roDPlPZzFKBe4GzgBJguZktDJ6j3OjHwOPuPtfMxhJ+/vIwYBdwgbtvM7NjgcXAoKjjrgierXzIuTsh19IVIiKtSaSFMAUodveN7l4LPAZcFJPHgdzgcx6wDcDdV7j7tiB9HZBlZpkHX+xPzz38rjEEEZH4EgkIg4AtUdslNP+WD3AncKWZlRBuHdwU5zyXAivcvSYq7cGgu+gndoi/uoeCiKAxBBGR+BIJCPEuoR6zfTmwwN0LgfOAh80scm4zOwb4JfCNqGOucPdxwCnB66q4P9xstpkVmVlRaWlpAsWNL9TYQlBEEBGJK5GAUAIMjtouJOgSinId8DiAuy8FsoA+AGZWCPwVuNrdNzQe4O5bg/e9wB8Jd0214O7z3H2yu08uKChIpE5xNbYQ1GMkIhJfIgFhOTDKzIabWQYwC1gYk2czMAPAzMYQDgilZtYTeBq4zd1fa8xsZmlm1hgw0oHzgbUHW5m2NI4haJaRiEh8BwwI7l4P3Eh4htC7hGcTrTOzOWZ2YZDte8DXzWwV8Chwrbt7cNxRwE9ippdmAovNbDWwEtgK3NfelYvWEBlDUEAQEYnngNNOAdx9EeHB4ui026M+vwOcHOe4nwE/a+W0kxIv5sFTl5GISNuS5k5lD4Xf1UIQEYkvaQKCpp2KiLQt+QKCIoKISFxJExA0qCwi0rakCQhaukJEpG1JExA0hiAi0rYkCgjhd7UQRETiS56AENJ9CCIibUmagKAxBBGRtiVNQGicZZSqQQQRkbiSJiBo6QoRkbYlTUBw3YcgItKmpAkImmUkItK2JAoIug9BRKQtyRMQgtVO1UAQEYkveQJCZFBZEUFEJJ6kCQiNFA5EROJLmoDQeGOaWggiIvElT0Ag6DI6zOUQETlSJRQQzGymma03s2IzuzXO/iFmtsTMVpjZajM7L2rfbcFx683snETP2d6aWgiH+ieJiHROBwwIZpYK3AucC4wFLjezsTHZfgw87u4TgVnA74JjxwbbxwAzgd+ZWWqC52xXHqnPofwpIiKdVyIthClAsbtvdPda4DHgopg8DuQGn/OAbcHni4DH3L3G3T8EioPzJXLOQ8LUaSQiEldaAnkGAVuitkuAE2Py3Ak8a2Y3ATnAmVHHvhFz7KDg84HOCYCZzQZmB5uVZrY+gTLH0wfYdcYvP+PRR5Y+wK7DXYh20FXqAarLkaqr1OVg6zE0kUyJBIR4X6k9ZvtyYIG7/9rMpgEPm9mxbRwbr2USe85wovs8YF4C5WyTmRW5++SDPc+RoKvUpavUA1SXI1VXqUtH1SORgFACDI7aLqSpS6jRdYTHCHD3pWaWRTiitXXsgc4pIiIdKJExhOXAKDMbbmYZhAeJF8bk2QzMADCzMUAWUBrkm2VmmWY2HBgFLEvwnCIi0oEO2EJw93ozuxFYDKQC8919nZnNAYrcfSHwPeA+M/sO4a6faz283vQ6M3sceAeoB77p7g0A8c55COoX7aC7nY4gXaUuXaUeoLocqbpKXTqkHtb4nAAREUluSXOnsoiItE0BQUREgCQJCB29TMbBMLP5ZrbTzNZGpfU2s+fM7IPgvVeQbmb2m6Beq83s+MNX8pbMbHCwpMm7ZrbOzG4O0jtdfcwsy8yWmdmqoC7/FqQPN7M3g7r8KZgkQTCR4k9BXd40s2GHs/yxghUDVpjZU8F2Z63HJjNbY2YrzawoSOt0f18AZtbTzJ4ws/eC/zPTOrouXT4g2GFYJuMgLSCYwhvlVuB5dx8FPB9sQ7hOo4LXbGBuB5UxUfXA99x9DDAV+Gbwu++M9akBznD344AJwEwzmwr8Erg7qMsewlOwCd73uPtRwN1BviPJzcC7UdudtR4Ap7v7hKh5+p3x7wvgHuAZdx8NHEf436dj6+LuXfoFTAMWR23fBtx2uMt1gDIPA9ZGba8HBgSfBwDrg8//D7g8Xr4j8QX8DTirs9cHyAbeJnx3/S4gLfZvjfAMumnB57Qgnx3usgflKSR8cTkDeIrwDaSdrh5BmTYBfWLSOt3fF+Glfz6M/d12dF26fAuB+EtvDGol75Gqn7tvBwje+wbpnaZuQVfDROBNOml9gm6WlcBO4DlgA1Du7vVBlujyRuoS7K8A8ju2xK36L+AHQPBgWfLpnPWA8DT3Z83sLQsvcwOd8+9rBOF7tx4MuvLuN7McOrguyRAQEll6o7PqFHUzs+7AX4Bvu/snbWWNk3bE1MfdG9x9AuFv2FOAMfGyBe9HZF3M7Hxgp7u/FZ0cJ+sRXY8oJ7v78YS7UL5pZqe2kfdIrksacDww18OrRu+jqXsonkNSl2QICIksvXGk+9jMBgAE7zuD9CO+bmaWTjgYPOLu/xMkd9r6ALh7OfAi4XGRnmbWeINndHkjdQn25wFlHVvSuE4GLjSzTYRXGT6DcIuhs9UDAHffFrzvBP5KOFB3xr+vEqDE3d8Mtp8gHCA6tC7JEBC6wjIZC4Frgs/XEO6Lb0y/OphxMBWoaGxeHgnMzIAHgHfd/T+jdnW6+phZgZn1DD53I7yi77vAEuCyIFtsXRrreBnwggedvYeTu9/m7oXuPozw/4UX3P0KOlk9AMwsx8x6NH4GzgbW0gn/vtx9B7DFzI4OkmYQXuGhY+tyuAdTOmjA5jzgfcJ9vj863OU5QFkfBbYDdYS/BVxHuM/2eeCD4L13kNcIz6DaAKwBJh/u8sfU5fOEm7GrgZXB67zOWB9gPLAiqMta4PYgfQTh9bmKgT8DmUF6VrBdHOwfcbjrEKdO04GnOms9gjKvCl7rGv9vd8a/r6B8E4Ci4G/sSaBXR9dFS1eIiAiQHF1GIiKSAAUEEREBFBBERCSggCAiIoACgoiIBBQQREQEUEAQEZHA/wchf1jTA8cmtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's define our prediction operation, that is the largest probability among our 10 possible output labels\n",
    "predict_operation = tf.argmax(y_hat, 1)\n",
    "# Let's define our accuracy operation\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(tf.equal(predict_operation,tf.argmax(y,1)),tf.float32))\n",
    " \n",
    "NUM_EPOCHS = 50 # Number of complte time through our traing data\n",
    "BATCH_SIZE = 50 # Training batches\n",
    "accuracies = []\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    train_model(sess, trX, trY, tstX, tstY, train_operation, accuracy_operation, NUM_EPOCHS, BATCH_SIZE, 10000)\n",
    "plt.ylim(.8,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many hidden neurons do I really need?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
