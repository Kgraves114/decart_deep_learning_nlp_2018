{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Introduction to Deep Learning Neural Networks\n",
    "\n",
    "### Can we model the Biological Neuron ?\n",
    "<BR>\n",
    "<img align=\"left\" style=\"float: l;\" src=\"./images/biological-nn1.png\" width=\"400px\">\n",
    "<img style=\"float: l;\" src=\"./images/biological-nn2.png\" width=\"400px\">\n",
    "<BR>\n",
    "<center><img src=\"./images/biological-nn3.png\" width=\"300px\"></center>\n",
    "<BR>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Basic Unit of a Neural Network\n",
    "\n",
    "### Let's look at the basic unit in a neural network known as the neuron\n",
    "<BR>\n",
    "<center><img src=\"./images/basic-nn.png\" width=\"600px\"></center>\n",
    "<BR>\n",
    "<center><img src=\"./images/formula1.png\" width=\"600px\"></center>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Finding Decsion Boundries\n",
    "<BR>\n",
    "<center><img src=\"./images/linear-separable.png\" width=\"600px\"></center>\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Perceptron Linear Classifier\n",
    "\n",
    "### Perceptions will always converge to a separable decision boundary if the data is linearly separable \n",
    "<BR>\n",
    "<img align=\"left\" style=\"float: l;\" src=\"./images/perceptron.png\" width=\"400px\">\n",
    "<img style=\"float: l;\" src=\"./images/perceptron-formula.png\" width=\"350px\">\n",
    "<BR>\n",
    "<BR>\n",
    "<center><img src=\"./images/formula1.png\" width=\"600px\"></center>\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Perceptron Beyond Linear Classification\n",
    "<BR>\n",
    "<center><img src=\"./images/xor.png\" width=\"600px\"></center>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Multilayer Fully Connected Networks\n",
    "\n",
    "### Fully connected networks are the classic starting point of neural networks.\n",
    "\n",
    "### Fully connected network consists of \n",
    "* Input layer\n",
    "* Several hidden layers\n",
    "* Output layer\n",
    "<BR>\n",
    "<img src=\"./images/topology.png\" width=\"500px\"> \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Training Neural Networks\n",
    "\n",
    "### Conceptual Understanding of Learning\n",
    "#### Let's say we have a neural network that takes this input and produces the output\n",
    "<BR>\n",
    "<img src=\"./images/bp1.png\" width=\"250px\"> \n",
    "### <center>Seems obvious that y = 2x</center>\n",
    "## Although with most real world datasets in deep neural networks it is not so easy to derive a mapping function\n",
    "    \n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Step 1 of Learning - Initialization\n",
    "\n",
    "### It is a common practice that we initialize the weights of our neural network to some random value.\n",
    "### That is to say the we start with a function <i>y = Wx</i>, where <i>W</i> represents our neural network weights.\n",
    "\n",
    "### So let's just assume that in our simple neural network the weights we randomly initialized as <i>y = 3x</i>. This is not the desired mapping function that we want, therefore, we will try to learn it! \n",
    "\n",
    "### What we desire is for our neural network to learn that the real mapping function is <i>y = 2x</i>.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "## Step 2 of Learning - Forward Propagation\n",
    "\n",
    "### We start with the input we have (i.e. training set) and we calculate the output based on the settings of our current network weights <i>W</i>.\n",
    "<BR>\n",
    "<img src=\"./images/bp2.png\" width=\"400px\"> \n",
    "\n",
    "### This step of our learning is called forward-propagation. Seems natural, we are going forward through our neural network.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Step 3 of Learning - Loss Function\n",
    "\n",
    "### At this point we have our actual output with the current weight settings <i>W</i> and the desired output we would like to see. \n",
    "\n",
    "<BR>\n",
    "<img src=\"./images/bp3.png\" width=\"400px\"> \n",
    "### We need some kind of a <b><i>performance metric</i></b> to tell us how well the neural network is reaching its goal of discovering the desired output. \n",
    "### To do this we will define a <b><i>loss function</i></b> that will tell us how close we are to the desired output while learning.\n",
    "\n",
    "### (a) How about <i>loss = | (desired output - actual output) |</i>\n",
    "###     We use the absolute value because we are interested in the absolute error. If we were to use <i>(desired output - actual output)</i> our loss function would return positive values when (prediction < desired output) and negative values when <i>(prediction > desired output)</i>. This would not produce an absolute error.\n",
    "\n",
    "### (b) Something is still wrong about this loss function ? \n",
    "###     Several situations can lead to the same sum of errors. For example lots of small errors or a few big errors can sum to the same loss! \n",
    "### It would be more favorable to have a lot of small errors rather than a few big errors.\n",
    "\n",
    "### (c) To get the behavior we want what is we <i>squared</i> the absolute errors. This would mean that small errors would be penalized less than large errors. This is exactly the behavior we desire.\n",
    "\n",
    "<center>$loss = J(f(x); y) = \\displaystyle \\frac{1}{2n}\\sum_{i=0}^n (y_i - f(x_i))^2$</center>\n",
    "<BR>\n",
    "<img src=\"./images/bp4.png\" width=\"600px\"> \n",
    "### Our goal is to minimize the overall loss over our entire training dataset.\n",
    "    \n",
    "### Simply put, our <i>loss function</i> is our <i>error metric</i> which tells us how much precision we lose. This is why we call it a <i>loss function</i>. Although you may also here it referred to as a <i>cost function</i>.\n",
    "***   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Differentiation\n",
    "\n",
    "### Since in our example we only have one weight to train we could use a brute force method of searching from say -500.0 to +500.0 stepping by 0.001. Then we could take the weight <i>W></i> that has the smallest sum of squared errors. \n",
    "\n",
    "### Although most neural networks have 1000s of weights to train and this would quickly become an intractable problem.\n",
    "\n",
    "### Fortunatly, we have a mathmatical method called <i>differentiation</i>. In mathmatics, the <i>derivative</i> of a function at a certain point  gives us the rate of spped at which the function is changing.\n",
    "\n",
    "### If we apply the <i>derivative</i> to our loss function we will know the rate at which a change in our weight value $\\delta$<i>W</i> will effect our loss or error. \n",
    "\n",
    "### So we will modify our weight <i>W</i> as follows\n",
    "\n",
    "## <center>$W_i := W_{i-1} - \\alpha\\frac{\\partial}{\\partial W}J(f(x); y)$</center>\n",
    "\n",
    "<BR>\n",
    "<img src=\"./images/gradient-descent.png\" width=\"600px\"> \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Step 5 - Back-propagation\n",
    "\n",
    "### Let's consider a linear example where we multiply 3 x to get the hidden layer, then multiply that by 2 times to produce the output.\n",
    "\n",
    "### input -> 3 x -> 2 h -> output\n",
    "\n",
    "### A change on the input weight of 0.001 will result in 0.006 change in the output.\n",
    "\n",
    "### input --> 6 x --> output\n",
    "\n",
    "### Similarly, an error on  the output of 0.006 can be backpropagated to and error of 0.003 on the hidden layer and 0.001 on the input layer.\n",
    "\n",
    "### Since differiention is decomposable, if we track differentiable functions where for each function we know how to forward-propagate (by directly applying the function) and how to back-propagate (by knowing the derivative of the function), we can compose any complex neural network and teach it to learn.\n",
    "\n",
    "\n",
    "### This process is known as auto-differentiation and only requires that each activation function is provided with the implementation of its derivative.\n",
    "\n",
    "<BR>\n",
    "<img src=\"./images/bp5.png\" width=\"400px\"> \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Step 6 - Weight Update\n",
    "\n",
    "### The derivative is just the rate of which the error changes relative to the weight changes.\n",
    "\n",
    "### <center><i>New weight = old weight — learning rate * Derivative Rate of loss function</i></center> \n",
    "## <center>$W_i := W_{i-1} - \\alpha\\frac{\\partial}{\\partial W}J(f(x); y)$</center>\n",
    "\n",
    "<BR>\n",
    "<img src=\"./images/gradient-descent.png\" width=\"600px\"> \n",
    "    \n",
    "### - If the derivative rate is positive, an increase in weight will increase error, thus the new weight should be smaller.\n",
    "### - If the derivative rate is negative, an increase in weight will decrease the error, thus we need to increase the weights.\n",
    "### - If the derivative is 0, it means we reached our minimum. We learned the optimal weight value.    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Step 7 - Iterate until convergence\n",
    "\n",
    "### we update weights with a small delta step known as our learning rate. SO it will take several iterations in order to learn our optimal weight parameters.\n",
    "\n",
    "<BR>\n",
    "<img src=\"./images/learning.gif\" width=\"500px\"> \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Overall picture\n",
    "\n",
    "<BR>\n",
    "<img src=\"./images/overall.png\" width=\"700px\"> \n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Activation Functions\n",
    "<BR>\n",
    "<img src=\"./images/activation.png\" width=\"800px\">\n",
    "\n",
    "#### Sigmoid Function \n",
    "* Outputs unnormalized (not symmetrical around zero)\n",
    "* Longer for gradient descent to converge\n",
    "* Can suffer from vanishing gradient and gradient saturation\n",
    "\t\n",
    "#### Hyperbolic Tangent: \n",
    "* Outputs normalized (centered around zero) \n",
    "* Gradient Descent converges faster\n",
    "* Can suffer from vanishing gradient and gradient saturation\n",
    "\n",
    "#### Rectified Linear Unit (ReLU): \n",
    "* Output f(x) = max(0, x)\n",
    "* Better addresses gradient saturation and vanishing gradient\n",
    "\n",
    "### Why do we care so much about the derivative of the activation function?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
